<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Revisiting Shapley Values: A Causal Perspective - 3&nbsp; Background</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./explanations.html" rel="next">
<link href="./framework.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Background</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Revisiting Shapley Values: A Causal Perspective</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framework.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Evaluation Framework</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./background.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Background</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./explanations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Shapley Explanations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discussion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Conclusion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">Appendix</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#causality" id="toc-causality" class="nav-link active" data-scroll-target="#causality"><span class="toc-section-number">3.1</span>  Causality</a></li>
  <li><a href="#shapley-value" id="toc-shapley-value" class="nav-link" data-scroll-target="#shapley-value"><span class="toc-section-number">3.2</span>  Shapley Value</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Background</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this section, we briefly review the key concepts from theories of causality and cooperative game theory necessary to understand the Shapley-based model explanation literature.</p>
<section id="causality" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="causality"><span class="header-section-number">3.1</span> Causality</h2>
<p>Although explanation and causality may at first appear to be separate topics, they are highly intertwined. <span class="citation" data-cites="miller_explanation_2018">Miller (<a href="references.html#ref-miller_explanation_2018" role="doc-biblioref">2018</a>)</span> reviews theories of explanation from the social sciences and demonstrates that notions of causality are central. While there are different philosophical theories of causality and frameworks for estimating causal effects, the XAI literature primarily leverages the formal model of causality introduced by Halpern and Pearl (see <span class="citation" data-cites="halpern_causes_2005-1">Halpern and Pearl (<a href="references.html#ref-halpern_causes_2005-1" role="doc-biblioref">2005a</a>)</span> and <span class="citation" data-cites="halpern_causes_2005">Halpern and Pearl (<a href="references.html#ref-halpern_causes_2005" role="doc-biblioref">2005b</a>)</span>).</p>
<p>Under this framework, questions are divided into three levels – referred to as the ladder of causality – each of which requires a different degree and type of causal information.</p>
<p>At the lowest level are “how” questions, which are associative and can be answered purely from observational data without any causal information. The second rung includes “what if’’ questions, which involve reasoning about the effects of interventions. These types of questions require either a randomized trial or assumptions about which variables are causally related. On the highest wrung are “would have” questions that involve reasoning about counterfactual scenarios, that is, what would have occurred had a different action been taken under identical circumstances. These types of questions require knowledge of the functional (i.e.&nbsp;mathematical) equations governing each relationship. Intuitively, counterfactual questions are distinct from interventional ones because knowing the outcome of the action taken changes our beliefs about the likely outcome of other actions under the same circumstances. A more rigorous exploration of these different levels and their differences can be found in <span class="citation" data-cites="pearl_causality_2009">Pearl (<a href="references.html#ref-pearl_causality_2009" role="doc-biblioref">2009</a>)</span>. However, we note that for model-level explanations, the distinction between interventional and counterfactual questions is functionally irrelevant as the model itself is sufficient to answer both types of questions.</p>
<p>In order to apply a causal perspective to Shapley-based model explanations, some familiarity with the formalisms from the causality literature is required. The remainder of this section introduces those formalisms in a limited way. For a more complete introduction to causal inference, see <span class="citation" data-cites="pearl_causal_2016">Pearl, Glymour, and Jewell (<a href="references.html#ref-pearl_causal_2016" role="doc-biblioref">2016</a>)</span>. An exhaustive treatment of the topic can be found in <span class="citation" data-cites="pearl_causality_2009">Pearl (<a href="references.html#ref-pearl_causality_2009" role="doc-biblioref">2009</a>)</span>.</p>
<p>The primary tool employed to answer “how” questions are conditional probabilities, which require no causal assumptions or additional information. For many practitioners, the lack of additional assumptions and an ability to forgo the complications involved in causal reasoning may be ideal. However, questions at this level are the least likely to align with an explainee’s target questions since human explanations typically involve “why” questions (<span class="citation" data-cites="miller_explanation_2018">Miller (<a href="references.html#ref-miller_explanation_2018" role="doc-biblioref">2018</a>)</span>).</p>
<p>In order to address “what if” questions on the second rung of the ladder of causality, practitioners must provide information about the causal relationships between variables. However, since the true causal relationships governing natural processes is unknown, this information is better framed as a set of causal assumptions. These assumptions are encoded using a formalism called a graphical causal model (GCM), which consists of a set of nodes and edges (<span class="math inline">\(\mathcal{G} = (V, E)\)</span>) that form a directed acyclic graph (DAG). The nodes of a GCM represent variables and each edge represents a causal relationship between the two variables. Just as importantly, a missing edge between two variables indicates the practitioner’s belief that no causal relationship exists.</p>
<p>A graphical causal model allows a practitioner – under certain conditions – to predict the effects of interventions from observational data. Observational data alone is insufficient because correlation between variables has two potential sources: either there is a causal relationship between the variables or there is an additional variable (called a confounder) that induces a spurious (i.e.&nbsp;non-causal) correlation (see <a href="#fig-confounder">Figure&nbsp;<span>3.2</span></a>). To understand how to differentiate between the two, it is helpful to first understand how a GCM can be used to predict the dependencies between variables.</p>
<p>A graphical causal model is sufficient to determine how two variables are related in observational data corresponding to that GCM. Specifically, a GCM can indicate whether two variables are independent, independent conditional on other variables, dependent, or dependent conditional on other variables<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. The simplest case are direct relationships, which indicate that two variables are unconditionally dependent. To assess implicit dependencies more generally, a GCM can be decomposed into a combination of three fundamental building blocks: chains, forks, and colliders (see <a href="#fig-gcm-building-blocks">Figure&nbsp;<span>3.1</span></a>). Each of these building blocks implies a different set of dependencies, which can be expressed in terms of expectations over the random variables involved.</p>
<p>In a chain (<a href="#fig-chain">Figure&nbsp;<span>3.1 (a)</span></a>), four relationships can be deduced. There are three direct connections. It is also true that <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span> are independent, conditional on <span class="math inline">\(X_2\)</span>.</p>
<div id="fig-gcm-building-blocks" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell quarto-layout-cell" data-fig-width="30%" data-file="figures/chain.dot" style="flex-basis: 33.3%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-chain" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 62.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 58,-184 58,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- X2 --> <g id="node2" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X1&#45;&gt;X2 --> <g id="edge1" class="edge">
<title>
X1-&gt;X2
</title>
<path fill="none" stroke="black" d="M27,-143.7C27,-135.98 27,-126.71 27,-118.11"></path> <polygon fill="black" stroke="black" points="30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1"></polygon> </g> <!-- Y --> <g id="node3" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X2&#45;&gt;Y --> <g id="edge2" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M27,-71.7C27,-63.98 27,-54.71 27,-46.11"></path> <polygon fill="black" stroke="black" points="30.5,-46.1 27,-36.1 23.5,-46.1 30.5,-46.1"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(a) Chain</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell quarto-layout-cell" data-fig-width="30%" data-file="figures/fork.dot" style="flex-basis: 33.3%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-fork" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 62.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 58,-184 58,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- X2 --> <g id="node2" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X1&#45;&gt;X2 --> <g id="edge1" class="edge">
<title>
X1-&gt;X2
</title>
<path fill="none" stroke="black" d="M27,-143.7C27,-135.98 27,-126.71 27,-118.11"></path> <polygon fill="black" stroke="black" points="30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1"></polygon> </g> <!-- Y --> <g id="node3" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X2&#45;&gt;Y --> <g id="edge2" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M27,-71.7C27,-63.98 27,-54.71 27,-46.11"></path> <polygon fill="black" stroke="black" points="30.5,-46.1 27,-36.1 23.5,-46.1 30.5,-46.1"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(b) Fork</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell quarto-layout-cell" data-fig-width="30%" data-file="figures/collider.dot" style="flex-basis: 33.3%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-collider" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- Y --> <g id="node2" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X1&#45;&gt;Y --> <g id="edge1" class="edge">
<title>
X1-&gt;Y
</title>
<path fill="none" stroke="black" d="M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2"></path> <polygon fill="black" stroke="black" points="53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64"></polygon> </g> <!-- X2 --> <g id="node3" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="99" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="99" y="-85.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X2&#45;&gt;Y --> <g id="edge2" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2"></path> <polygon fill="black" stroke="black" points="78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(c) Collider</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.1: Building Blocks of a Graphical Causal Model</figcaption><p></p>
</figure>
</div>
<ol type="1">
<li><span class="math inline">\((X_2, X_1)\)</span> are dependent: <span class="math inline">\(E[X_2 | X_1] \neq E[X_2]\)</span></li>
<li><span class="math inline">\((Y, X_2)\)</span> are dependent: <span class="math inline">\(E[Y|X_2] \neq E[Y]\)</span></li>
<li><span class="math inline">\((Y, X_1)\)</span> are dependent: <span class="math inline">\(E[Y|X_1] \neq E[Y]\)</span></li>
<li><span class="math inline">\((Y, X_1)\)</span> are independent, conditional on <span class="math inline">\(X_2\)</span>: <span class="math inline">\(E[Y|X_1, X_2] = E[Y|X_2]\)</span></li>
</ol>
<p>In a fork <a href="#fig-fork">Figure&nbsp;<span>3.1 (b)</span></a>, there is a variable <span class="math inline">\(X_1\)</span> that is a common cause of the other two. In addition to the the relationships implied by the direct edges, we also have the following relationships:</p>
<ol type="1">
<li><span class="math inline">\((Y, X_2)\)</span> are dependent: <span class="math inline">\(E[Y|X_2] \neq E[Y]\)</span></li>
<li><span class="math inline">\((Y, X_2\)</span> are independent, conditional on <span class="math inline">\(X_1\)</span>: <span class="math inline">\(E[Y|X_1, X_2] = E[Y|X_1]\)</span></li>
</ol>
<p>In a collider <a href="#fig-collider">Figure&nbsp;<span>3.1 (c)</span></a>, there is a variable <span class="math inline">\(Y\)</span> that is directly influenced by both of the other variables. Conditioning on a collider induces dependence between two otherwise-independent variables:</p>
<ol type="1">
<li><span class="math inline">\(X_1\)</span> is independent of <span class="math inline">\(X_2\)</span>: <span class="math inline">\(E[X_1|X_2] = E[X_1]\)</span></li>
<li><span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are dependent, conditional on <span class="math inline">\(Y\)</span>: <span class="math inline">\(E[X_1|X_2, Y] \neq E[X_1|Y]\)</span></li>
</ol>
<p>Together, these building blocks can be used to construct a complete set of dependencies implied by a GCM. The next step is to be able to differentiate between causal and non-causal sources of dependence.</p>
<p>Spurious correlations can be identified by looking for “backdoor” paths between variables. In <a href="#fig-confounder">Figure&nbsp;<span>3.2</span></a>, there is one direct relationship between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(Y\)</span> and one backdoor path <span class="math inline">\((X_1 \leftarrow X_2 \rightarrow Y)\)</span>. Applying the rules above demonstrates how this path introduces additional non-causal dependence (correlation). A backdoor path can be closed in two ways: conditioning and colliders. The path <span class="math inline">\(X_1 \rightarrow X_2 \rightarrow Y\)</span> is a chain and therefore (using the rules from earlier) conditioning on <span class="math inline">\(X_2\)</span> makes <span class="math inline">\(X_1\)</span> and <span class="math inline">\(Y\)</span> independent, effectively “closing” that backdoor path. If there is a collider along a backdoor path, then that path is closed and conditioning on the collider has the negative consequence of opening the backdoor path. When there exists a set of variables <span class="math inline">\(\mathbf{Z}\)</span> that close all backdoor paths between a pair of variables (e.g.&nbsp;<span class="math inline">\((X_1, Y)\)</span>), the backdoor criterion (<span class="citation" data-cites="pearl_causality_2009">Pearl (<a href="references.html#ref-pearl_causality_2009" role="doc-biblioref">2009</a>)</span>) is satisfied and the interventional effect of <span class="math inline">\(X_1\)</span> on <span class="math inline">\(Y\)</span> can be estimated. However, the set of variables <span class="math inline">\(\mathbf{Z}\)</span> may not exist, meaning that the desired interventional quantity is not identifiable from observational data alone.</p>
<div class="cell" data-file="figures/confounder.dot">
<div class="cell-output-display">
<div id="fig-confounder" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="672" height="480" viewbox="0.00 0.00 89.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 85,-184 85,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- Y --> <g id="node2" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="54" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="54" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X1&#45;&gt;Y --> <g id="edge1" class="edge">
<title>
X1-&gt;Y
</title>
<path fill="none" stroke="black" d="M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35"></path> <polygon fill="black" stroke="black" points="47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55"></polygon> </g> <!-- X2 --> <g id="node3" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="54" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="54" y="-157.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X2&#45;&gt;X1 --> <g id="edge2" class="edge">
<title>
X2-&gt;X1
</title>
<path fill="none" stroke="black" d="M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35"></path> <polygon fill="black" stroke="black" points="40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03"></polygon> </g> <!-- X2&#45;&gt;Y --> <g id="edge3" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01"></path> <polygon fill="black" stroke="black" points="62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.2: Confounding in a Graphical Causal Model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Intervening on a variable is equivalent to forcing it to take on some value irrespective of the other factors that would typically influence it. Graphically, this is equivalent to removing all of the incoming edges to the variable. For example, an intervention on <span class="math inline">\(X_1\)</span> in <a href="#fig-confounding-pre-intervention">Figure&nbsp;<span>3.3 (a)</span></a> can be represented graphically by removing the edge <span class="math inline">\((X_1, X_2)\)</span>. Importantly, the graphs in <a href="#fig-confounding-pre-intervention">Figure&nbsp;<span>3.3 (a)</span></a> and <a href="#fig-confounding-post-intervention">Figure&nbsp;<span>3.3 (b)</span></a> imply different sets of dependencies, which demonstrates a more general point that an interventional conditional distribution is not always equivalent to the corresponding observational conditional distribution. Notationally, the do-operator (<span class="citation" data-cites="pearl_causality_2009">Pearl (<a href="references.html#ref-pearl_causality_2009" role="doc-biblioref">2009</a>)</span>) is used to differentiate between expectations over these two types of distributions: <span class="math inline">\(E[Y=y | do(X_1=x_1)] \neq E[Y=y | X_1=x_1]\)</span>. To estimate the interventional effect of <span class="math inline">\(X_1\)</span> on <span class="math inline">\(Y\)</span>, we condition on <span class="math inline">\(X_2\)</span>, which closes the only backdoor path <span class="math inline">\(X_1 \leftarrow X_2 \rightarrow Y\)</span>, and therefore satisfies the backdoor criterion.</p>
<p><span class="math display">\[\begin{align}
    P(Y = y | do(X_1=x_1) &amp;= \sum_z P(Y=y | X_1=x_1, X_2 = x_2)P(X_2=x_2) \\
    E[y| do(x_1)] &amp;= \sum_{x_2} E[y|x_1, x_2]p(x_2)
\end{align}\]</span></p>
<p>Provided that a set of variables satisfying the backdoor criterion can be identified, a GCM allows a practitioner to predict interventional effects from purely observational data thereby addressing “what if” questions on the second rung of the ladder of causality. However, a GCM alone is still insufficient to answer “why” questions, which require counterfactual reasoning.</p>
<div id="fig-intervention" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell quarto-layout-cell" data-fig-width="45%" data-file="figures/confounder.dot" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-confounding-pre-intervention" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 89.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 85,-184 85,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- Y --> <g id="node2" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="54" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="54" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X1&#45;&gt;Y --> <g id="edge1" class="edge">
<title>
X1-&gt;Y
</title>
<path fill="none" stroke="black" d="M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35"></path> <polygon fill="black" stroke="black" points="47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55"></polygon> </g> <!-- X2 --> <g id="node3" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="54" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="54" y="-157.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X2&#45;&gt;X1 --> <g id="edge2" class="edge">
<title>
X2-&gt;X1
</title>
<path fill="none" stroke="black" d="M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35"></path> <polygon fill="black" stroke="black" points="40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03"></polygon> </g> <!-- X2&#45;&gt;Y --> <g id="edge3" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01"></path> <polygon fill="black" stroke="black" points="62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(a) Pre-Intervention</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell quarto-layout-cell" data-fig-width="45%" data-file="figures/confounder_post_intervention.dot" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-confounding-post-intervention" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- Y --> <g id="node2" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X1&#45;&gt;Y --> <g id="edge1" class="edge">
<title>
X1-&gt;Y
</title>
<path fill="none" stroke="black" d="M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2"></path> <polygon fill="black" stroke="black" points="53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64"></polygon> </g> <!-- X2 --> <g id="node3" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="99" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="99" y="-85.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X2&#45;&gt;Y --> <g id="edge2" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2"></path> <polygon fill="black" stroke="black" points="78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(b) Post-Intervention</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.3: Interventions Modify the Graphical Causal Model</figcaption><p></p>
</figure>
</div>
<p>In order to evaluate counterfactual scenarios associated with questions at the top of the ladder of causality, a structural causal model (SCM) is often required. Whereas a GCM only requires information about whether or not causal relationships between pairs of variables exist, a SCM requires the functional (e.g.&nbsp;mathematical) equations governing those relationships. Formally, a SCM It is comprised of four components: a set of exogenous “noise” variables <span class="math inline">\(U\)</span> whose values are assumed to be determined outside of the SCM, a joint distribution <span class="math inline">\(P_U\)</span> over these exogenous variables, a set of endogenous variables <span class="math inline">\(V\)</span> whose values are determined by the SCM, and a set of functions <span class="math inline">\(F = \{f_1, f_2, ...\}\)</span> where each <span class="math inline">\(f_i\)</span> assigns values to variables in <span class="math inline">\(V\)</span> based on the values of the other variables. Every SCM has an associated GCM whose nodes are the endogenous variables and the directed edges represent the causal relationships captured by the equations in <span class="math inline">\(F\)</span>. For simplicity, exogenous variables are typically omitted from the GCM. Every endogenous variable must be a descendent of at least one exogenous variable and exogenous variables cannot be descendants of any other variable. Therefore, each endogenous variable can be written as a function of its parents (denoted <span class="math inline">\(Pa(\cdot)\)</span>) and the associated noise variable:</p>
<p><span class="math display">\[
X_i = f_i(Pa(X_i), U_i)
\]</span></p>
<p>With this foundation, we can now see how model level questions at any level can be addressed using only the model (<a href="#fig-levels-of-explanation">Figure&nbsp;<span>3.4</span></a>). For simplicity, assume we have just two features <span class="math inline">\(X_1, X_2\)</span> with associated noise terms <span class="math inline">\(U_1, U_2\)</span>. There are three endogenous variables <span class="math inline">\(V = \{Y, X_1, X_2\}\)</span> representing the 2 features and the output of the model. Since we are interested in a model level explanation, every feature <span class="math inline">\(X_i\)</span> has an edge pointing to <span class="math inline">\(\hat{Y}\)</span> and no other edges between them. Therefore, <span class="math inline">\(f_1, f_2\)</span> are functions of the noise terms only and <span class="math inline">\(f_{Y}\)</span> is the model itself, which is deterministic and therefore has no additional noise term. The SCM is fully specified, so counterfactual questions can be addressed, which means that interventional and associative questions are also addressable.</p>
<div id="fig-levels-of-explanation" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell quarto-layout-cell" data-fig-width="45%" data-file="figures/confounder_post_intervention.dot" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-model-level" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- Y --> <g id="node2" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X1&#45;&gt;Y --> <g id="edge1" class="edge">
<title>
X1-&gt;Y
</title>
<path fill="none" stroke="black" d="M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2"></path> <polygon fill="black" stroke="black" points="53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64"></polygon> </g> <!-- X2 --> <g id="node3" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="99" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="99" y="-85.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X2&#45;&gt;Y --> <g id="edge2" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2"></path> <polygon fill="black" stroke="black" points="78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(a) Model Level</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell quarto-layout-cell" data-fig-width="45%" data-file="figures/confounder.dot" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-world-level" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
<svg width="NaN" height="480" viewbox="0.00 0.00 89.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 85,-184 85,4 -4,4"></polygon> <!-- X1 --> <g id="node1" class="node">
<title>
X1
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X1</text> </g> <!-- Y --> <g id="node2" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="54" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="54" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- X1&#45;&gt;Y --> <g id="edge1" class="edge">
<title>
X1-&gt;Y
</title>
<path fill="none" stroke="black" d="M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35"></path> <polygon fill="black" stroke="black" points="47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55"></polygon> </g> <!-- X2 --> <g id="node3" class="node">
<title>
X2
</title>
<ellipse fill="none" stroke="black" cx="54" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="54" y="-157.8" font-family="Times,serif" font-size="14.00">X2</text> </g> <!-- X2&#45;&gt;X1 --> <g id="edge2" class="edge">
<title>
X2-&gt;X1
</title>
<path fill="none" stroke="black" d="M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35"></path> <polygon fill="black" stroke="black" points="40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03"></polygon> </g> <!-- X2&#45;&gt;Y --> <g id="edge3" class="edge">
<title>
X2-&gt;Y
</title>
<path fill="none" stroke="black" d="M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01"></path> <polygon fill="black" stroke="black" points="62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29"></polygon> </g> </g>
</svg>
</p>
<p></p><figcaption class="figure-caption">(b) World Level</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.4: Levels of Explanation</figcaption><p></p>
</figure>
</div>
<p>Following a similar argument, we can also see how world-level explanations cannot always be addressed without additional information. Given the same setup as in the previous example, but with the edge <span class="math inline">\((X_2, X_1)\)</span> (see <a href="#fig-world-level">Figure&nbsp;<span>3.4 (b)</span></a>). We now have <span class="math inline">\(Pa(X_1) = \{X_2, U_1\}\)</span>, however, we have not specified a corresponding function <span class="math inline">\(f_1\)</span> that includes both of these terms. Therefore, the SCM is under-specified and counterfactual questions cannot be addressed. However, interventional questions can be addressed because there exists a set of variables satisfying the backdoor criterion for estimating the two interventional quantities of interest: <span class="math inline">\(P(Y = y | do(X_1 = x_1))\)</span> and <span class="math inline">\(P(Y = y | do(X_2 = x_2)\)</span>. For the first case, we condition on <span class="math inline">\(X_2\)</span> to close the backdoor path <span class="math inline">\((X_1, X_2, Y)\)</span>. In the second case, no conditioning is required since the post-intervention graph is the same as the pre-intervention graph.</p>
<p>In this section, we reviewed the core components of Pearl-style causality, namely, the degree and type of causal information required to address questions on different rungs of the ladder of causality. We have also provided an initial preview of how these formalisms (GCMs and SCMs) are connected to the task of generating model explanations. For explanatory questions targeting world-level model explanations, the usual hierarchy of required causal information applies. However, for model-level explanations, the model itself is sufficient for generating explanations that can address questions at all rungs. Therefore, from a causal perspective, understanding the desired level of explanation is essential to understand whether any auxiliary causal information is required. We will return to these ideas in later sections, but first, some additional background on Shapley values is required.</p>
</section>
<section id="shapley-value" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="shapley-value"><span class="header-section-number">3.2</span> Shapley Value</h2>
<p>Game theory explores the strategic behavior and interactions between rational agents in the context of well-defined games. Cooperative game theory is a sub-field that focuses on games in which groups of players (coalitions) compete against other groups of players and receive a combined payout (gain), or alternatively, incur a total cost<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. A cooperative game is defined by a set of players called the grand coalition <span class="math inline">\(\mathcal{C} = \{1, 2, ..., N\}\)</span> and a value function<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <span class="math inline">\(v\)</span>, which specifies the real-valued payout every group of players <span class="math inline">\(S \subseteq \mathcal{C}\)</span> receives when they cooperate. More formally, <span class="math inline">\(v\)</span> is a set function <span class="math inline">\(v: \mathcal{P}(C) \rightarrow \mathbb{R}\)</span> such that <span class="math inline">\(v(S) \in \mathcal{R}\)</span> and where <span class="math inline">\(\mathcal{P}(\mathcal{C})\)</span> denotes the power set of the grand coalition. Since the payout is received by the group, there is a further complication regarding how to fairly allocate the group’s winnings to individual players, referred to as the attribution problem.</p>
<p>The Shapley value (<span class="citation" data-cites="shapley_value_1953">Shapley (<a href="references.html#ref-shapley_value_1953" role="doc-biblioref">1953</a>)</span>) is a solution concept from cooperative game theory that produces an allocation strategy for fairly distributing payoffs to each player in a coalition. It can be viewed as the marginal contribution of each player to the coalition, averaged over all possible orderings of the players. To build intuition for how this solves the attribution problem, consider the following example.</p>
<p>A factory employs three workers <span class="math inline">\((w_1, w_2, w_3)\)</span>, each of whom has agreed to be paid in proportional to their contribution to the factory’s widget output. Employees are required to work a fixed number of hours each week, but they are allowed to set their own schedules. The factory owner has decided to use Shapley values to set each employee’s wage and has collected data on factory output when different workers are present. In this scenario, the workers are the players in the game and the value function is captured by the hourly factory production for every combination of workers (see <a href="#tbl-productivity">Table&nbsp;<span>3.1</span></a>).</p>
<div id="tbl-productivity" class="anchored">
<table class="table">
<caption>Table&nbsp;3.1: Worker Productivity</caption>
<thead>
<tr class="header">
<th style="text-align: center;">workers</th>
<th style="text-align: center;">widgets/hour</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\emptyset\)</span></td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_1\)</span></td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_2\)</span></td>
<td style="text-align: center;">5</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_3\)</span></td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_1, w_2\)</span></td>
<td style="text-align: center;">8</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_1, w_3\)</span></td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_2, w_3\)</span></td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_1, w_2, w_3\)</span></td>
<td style="text-align: center;">12</td>
</tr>
</tbody>
</table>
</div>
<p>The Shapley value for each worker is the number of additional widgets per hour (marginal contribution) produced when they arrive at the factory, averaged over all possible arrival orders. The marginal contribution of each worker <span class="math inline">\(i\)</span> to a coalition <span class="math inline">\(S\)</span> (columns 2-4 of <a href="#tbl-productivity">Table&nbsp;<span>3.1</span></a>) is the additional value generated when worker <span class="math inline">\(i\)</span> arrives<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p><span id="eq-marginal-value"><span class="math display">\[
\Delta(i, S) = v(S \cup i) - v(S)
\tag{3.1}\]</span></span></p>
<p>Let <span class="math inline">\(\Pi\)</span> denote the set of all orderings of the players in <span class="math inline">\(C\)</span>. Given player <span class="math inline">\(i\)</span> and a permutation <span class="math inline">\(\pi \in \Pi\)</span>, let <span class="math inline">\(S\)</span> be the set of all players preceding player <span class="math inline">\(i\)</span> in <span class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[
S_{i, \pi} = \{j: \pi(j) &lt; \pi(i)\}
\]</span> {# eq-arrival-order}</p>
<p>The Shapley value for player <span class="math inline">\(i\)</span> can then be expressed as:</p>
<p><span id="eq-permutation-shapley-formula"><span class="math display">\[
\phi(i) = \frac{1}{N!} \sum_{\pi \in \Pi} \Delta(i, S_{i, \pi})
\tag{3.2}\]</span></span></p>
<p>The last row of <a href="#tbl-sv-by-worker">Table&nbsp;<span>3.2</span></a> computes the Shapley value for each worker (denoted as <span class="math inline">\(\phi_i\)</span>) using this formulation, which relies on the information in <a href="#tbl-productivity">Table&nbsp;<span>3.1</span></a>.</p>
<div id="tbl-sv-by-worker" class="anchored">
<table class="table">
<caption>Table&nbsp;3.2: Shapley Value by Worker</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">order</th>
<th style="text-align: center;"><span class="math inline">\(\Delta(w_1)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\Delta(w_2)\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\Delta(w_3)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_1, w_2, w_3\)</span></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_1, w_3, w_2\)</span></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_2, w_1, w_3\)</span></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_2, w_3, w_1\)</span></td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_3, w_1, w_2\)</span></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_3, w_2, w_1\)</span></td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Shapley Value</td>
<td style="text-align: center;"><span class="math inline">\(\phi_1 = \frac{5+5+3+6+5+6}{6} = 5\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phi_2 = \frac{3+2+5+5+2+1}{6} = 3\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phi_3 = \frac{4+5+2+1+5+5}{6} = 4\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>The Shapley value can be expressed in an equivalent way based on the number of unique subsets of the grand coalition <span class="math inline">\(S \subseteq C\)</span> and the number of permutations of <span class="math inline">\(C\)</span> for which some ordering of players in <span class="math inline">\(S\)</span> immediately precedes the <span class="math inline">\(i\)</span>th player. The initial proof of the equivalence of these two formulations can be found in <span class="citation" data-cites="shapley_value_1953">Shapley (<a href="references.html#ref-shapley_value_1953" role="doc-biblioref">1953</a>)</span> and is reproduced in an expanded fashion in <span class="citation" data-cites="strumbelj_explaining_2009">Štrumbelj, Kononenko, and Robnik Šikonja (<a href="references.html#ref-strumbelj_explaining_2009" role="doc-biblioref">2009</a>)</span>.</p>
<p><span id="eq-alternative-shapley-formula"><span class="math display">\[
\phi(i) = \frac{1}{N!} \sum_{S \subseteq C \backslash \{i\}} |S|!(N-|S| - 1)! \Delta(i, S)
\tag{3.3}\]</span></span></p>
<p>One of the primary motivations for the use of the Shapley value is that it can be derived axiomatically. Given the following three axioms, the Shapley value not only solves the attribution problem, but can be shown to be the unique solution.</p>
<ol type="1">
<li><strong>Efficiency</strong>: The Shapley values for individual players sum up to the payout received by the grand coalition: <span class="math inline">\(\sum_{i \in C} \phi(i) = v(C) - v(\emptyset)\)</span>.</li>
<li><strong>Symmetry</strong>: If two players make equal contributions to all possible coalitions, then they should receive equal payouts. For players <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, if <span class="math inline">\(\Delta(i, S) = \Delta(j, S)\)</span> for all subsets <span class="math inline">\(S \subset C\)</span>, then <span class="math inline">\(\phi(i) = \phi(j)\)</span>.</li>
<li><strong>Dummy/Nullity/Sensitivity</strong>: If a player’s marginal contribution to all coalitions is zero (e.g.&nbsp;they never increase the payout of any coalition), then they should receive zero payout. For any player <span class="math inline">\(i\)</span>, if <span class="math inline">\(\Delta(i, S) = 0\)</span> for all <span class="math inline">\(S \subset N\)</span>, then <span class="math inline">\(\phi(i) = 0\)</span>.</li>
<li><strong>Linearity/Additivity</strong>: Given two games defined by value functions <span class="math inline">\(v\)</span> and <span class="math inline">\(v'\)</span>, the Shapley value for each player in the combined game is the sum of the allocations in each individual game: <span class="math inline">\(\phi_{v' + v}(i) = \phi_v(i) + \phi_{v'}(i)\)</span>.</li>
</ol>
<p>While this axiomatic grounding is both powerful and compelling, it is not factored into our human-centric evaluation framework and therefore plays a rather limited role in our discussion of Shapley-based model explanations. With the necessary background on Shapley values and Pearl-style causality in place, we are now in a position to examine the Shapley explanation literature using this proposed framework.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-halpern_causes_2005-1" class="csl-entry" role="doc-biblioentry">
Halpern, Joseph Y., and Judea Pearl. 2005a. <span>“Causes and <span>Explanations</span>: <span>A</span> <span>Structural</span>-<span>Model</span> <span>Approach</span>. <span>Part</span> <span>I</span>: <span>Causes</span>.”</span> <em>The British Journal for the Philosophy of Science</em> 56 (4): 843–87. <a href="http://www.jstor.org/stable/3541870">http://www.jstor.org/stable/3541870</a>.
</div>
<div id="ref-halpern_causes_2005" class="csl-entry" role="doc-biblioentry">
———. 2005b. <span>“Causes and <span>Explanations</span>: <span>A</span> <span>Structural</span>-<span>Model</span> <span>Approach</span>. <span>Part</span> <span>II</span>: <span>Explanations</span>.”</span> <em>The British Journal for the Philosophy of Science</em> 56 (4): 889–911. <a href="https://www.jstor.org/stable/3541871">https://www.jstor.org/stable/3541871</a>.
</div>
<div id="ref-miller_explanation_2018" class="csl-entry" role="doc-biblioentry">
Miller, Tim. 2018. <span>“Explanation in <span>Artificial</span> <span>Intelligence</span>: <span>Insights</span> from the <span>Social</span> <span>Sciences</span>.”</span> <em>arXiv:1706.07269 [Cs]</em>, August. <a href="http://arxiv.org/abs/1706.07269">http://arxiv.org/abs/1706.07269</a>.
</div>
<div id="ref-pearl_causality_2009" class="csl-entry" role="doc-biblioentry">
Pearl, Judea. 2009. <em>Causality: <span>Models</span>, <span>Reasoning</span>, and <span>Inference</span></em>. Second. Cambridge University Press.
</div>
<div id="ref-pearl_causal_2016" class="csl-entry" role="doc-biblioentry">
Pearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. <em>Causal <span>Inference</span> in <span>Statistics</span>: <span>A</span> <span>Primer</span></em>. Wiley.
</div>
<div id="ref-shapley_value_1953" class="csl-entry" role="doc-biblioentry">
Shapley, L. 1953. <span>“A <span>Value</span> for n-<span>Person</span> <span>Games</span>.”</span> In <em>Contributions to the <span>Theory</span> of <span>Games</span></em>, 2:307–17. Princeton, NJ: Princeton University Press.
</div>
<div id="ref-strumbelj_explaining_2009" class="csl-entry" role="doc-biblioentry">
Štrumbelj, E., I. Kononenko, and M. Robnik Šikonja. 2009. <span>“Explaining Instance Classifications with Interactions of Subsets of Feature Values.”</span> <em>Data &amp; Knowledge Engineering</em> 68 (10): 886–904. <a href="https://doi.org/10.1016/j.datak.2009.01.004">https://doi.org/10.1016/j.datak.2009.01.004</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>There are certain cases where these dependencies do not hold, so it is more accurate to say that the variables are <em>likely</em> dependent. For the ease of exposition, we exclude this modifier.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Other work use the terms coalitional game theory, and correspondingly, coalitional games<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Also referred to as a characteristic or contribution function<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>There are different ways to indicate the relationship between <span class="math inline">\(i\)</span>, <span class="math inline">\(S\)</span>, and <span class="math inline">\(v\)</span>. For example, <span class="math inline">\(\Delta_v(i, S)\)</span>, <span class="math inline">\(\Delta_{i, S}(v)\)</span>, and $ _{i, S}$ are all used in the literature. However, since a cooperative game is partially defined by the value function, we choose to leave the dependence on <span class="math inline">\(v\)</span> implicit in order to simplify the notation<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./framework.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Evaluation Framework</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./explanations.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Shapley Explanations</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>